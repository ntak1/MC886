{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MC886 Assigment 1\n",
    "\n",
    "## Objective:\n",
    "Use linear regression model to predict the prices of diamonds given their atributes. The data set might be found on:\n",
    "https://www.kaggle.com/shivam2503/diamonds.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data/diamonds.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "with open(data_dir, 'rb') as csvfile:\n",
    "    dataset = pd.read_csv(data_dir)\n",
    "    \n",
    "print(type(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0            Ideal\n",
      "1          Premium\n",
      "2             Good\n",
      "3          Premium\n",
      "4             Good\n",
      "5        Very Good\n",
      "6        Very Good\n",
      "7        Very Good\n",
      "8             Fair\n",
      "9        Very Good\n",
      "10            Good\n",
      "11           Ideal\n",
      "12         Premium\n",
      "13           Ideal\n",
      "14         Premium\n",
      "15         Premium\n",
      "16           Ideal\n",
      "17            Good\n",
      "18            Good\n",
      "19       Very Good\n",
      "20            Good\n",
      "21       Very Good\n",
      "22       Very Good\n",
      "23       Very Good\n",
      "24       Very Good\n",
      "25       Very Good\n",
      "26         Premium\n",
      "27       Very Good\n",
      "28       Very Good\n",
      "29       Very Good\n",
      "           ...    \n",
      "53910      Premium\n",
      "53911      Premium\n",
      "53912      Premium\n",
      "53913         Good\n",
      "53914         Good\n",
      "53915        Ideal\n",
      "53916         Good\n",
      "53917    Very Good\n",
      "53918      Premium\n",
      "53919        Ideal\n",
      "53920    Very Good\n",
      "53921    Very Good\n",
      "53922    Very Good\n",
      "53923        Ideal\n",
      "53924        Ideal\n",
      "53925        Ideal\n",
      "53926        Ideal\n",
      "53927         Good\n",
      "53928      Premium\n",
      "53929        Ideal\n",
      "53930      Premium\n",
      "53931      Premium\n",
      "53932    Very Good\n",
      "53933    Very Good\n",
      "53934      Premium\n",
      "53935        Ideal\n",
      "53936         Good\n",
      "53937    Very Good\n",
      "53938      Premium\n",
      "53939        Ideal\n",
      "Name: cut, Length: 53940, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#carat\tcut\tcolor\tclarity\tdepth\ttable\tprice\tx\ty\tz\n",
    "print(dataset['cut'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the data\n",
    "\n",
    "### 1. Split data in training, validation and test\n",
    "A wise person said: \"friends donâ€™t let friends use testing data for training\".  Set bellow the sizes of each set.\n",
    "\n",
    "**Note:**\n",
    "* **sklearn.model_selection.train_test_split(*arrays, **options)**  \n",
    "    Split arrays or matrices into random train and test subsets.  \n",
    "    See documentation:http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "\n",
    "### 2. Put the dataset into Numpy volume\n",
    "Categorical atributes are changed to integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_size:  53940\n",
      "train_size:  30000\n",
      "validation_size:  10000\n",
      "test_size:  13940\n"
     ]
    }
   ],
   "source": [
    "#1. SPLIT DATASET\n",
    "data_size = 53940        #change values here\n",
    "train_size = 30000\n",
    "validation_size = 10000\n",
    "test_size = 13940\n",
    "\n",
    "nx = 9                   #number of features of the input\n",
    "ny = 1                   #number of fetures of the output\n",
    "\n",
    "train,test_validation = train_test_split(dataset, test_size = validation_size + test_size)\n",
    "validation, test = train_test_split(test_validation, test_size = test_size)\n",
    "\n",
    "print (\"data_size: \", data_size)\n",
    "print (\"train_size: \", train.shape[0])\n",
    "print (\"validation_size: \", validation.shape[0])\n",
    "print (\"test_size: \", test.shape[0])\n",
    "\n",
    "\n",
    "#2. SAVE THE PANDA'S DATAFRAME ON NUMPY ARRAYS\n",
    "categorical_labels = ['carat', 'cut', 'color', 'clarity', 'depth', 'table', 'price', 'x', 'y', 'z']\n",
    "\n",
    "train_volume = np.empty(train.shape)\n",
    "validation_volume = np.empty(validation.shape)\n",
    "test_volume = np.empty(test.shape)\n",
    "\n",
    "# For each feature, copy or transforms and copy (in categorical case) to the correspondent volume\n",
    "for i in range(len(categorical_labels)):\n",
    "    if( i >= 1 and i <= 3): #if the feature is categorical\n",
    "        train_volume [:,i] = label_encoder.fit_transform(train[categorical_labels[i]])\n",
    "        validation_volume[:, i] = label_encoder.fit_transform(validation[categorical_labels[i]])\n",
    "        test_volume[:, i] = label_encoder.fit_transform(test[categorical_labels[i]])\n",
    "    else:\n",
    "        train_volume[:,i] = train[categorical_labels[i]]\n",
    "        validation_volume[:,i] = validation[categorical_labels[i]]\n",
    "        test_volume[:,i] = test[categorical_labels[i]]\n",
    "\n",
    "# Separates the input from the label organize data in (number_features, number_of_examples)\n",
    "x_train = (train_volume[:, 0:9]).T\n",
    "y_train = (train_volume[:, 9].reshape(train_size,1)).T\n",
    "x_validation = validation_volume [:, 0:9].T\n",
    "y_validation = validation_volume [:,9].reshape(ny, validation_size)\n",
    "x_test = test_volume [:,0:9].T\n",
    "y_test = test_volume [:,9].reshape(test_size,1).T\n",
    "\n",
    "# Sanity check\n",
    "assert(x_train.shape == (nx, train_size))\n",
    "assert(y_train.shape == (ny, train_size))\n",
    "assert(x_validation.shape == (nx, validation_size))\n",
    "assert(y_validation.shape == (ny, validation_size))\n",
    "assert(x_test.shape == (nx, test_size))\n",
    "assert(y_test.shape == (ny, test_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
