{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MC886 Assigment 1\n",
    "\n",
    "## Objective:\n",
    "Use linear regression model to predict the prices of diamonds given their atributes. The data set might be found on:\n",
    "https://www.kaggle.com/shivam2503/diamonds.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data/diamonds.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "with open(data_dir, 'rb') as csvfile:\n",
    "    dataset = pd.read_csv(data_dir)\n",
    "    \n",
    "print(type(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0            Ideal\n",
      "1          Premium\n",
      "2             Good\n",
      "3          Premium\n",
      "4             Good\n",
      "5        Very Good\n",
      "6        Very Good\n",
      "7        Very Good\n",
      "8             Fair\n",
      "9        Very Good\n",
      "10            Good\n",
      "11           Ideal\n",
      "12         Premium\n",
      "13           Ideal\n",
      "14         Premium\n",
      "15         Premium\n",
      "16           Ideal\n",
      "17            Good\n",
      "18            Good\n",
      "19       Very Good\n",
      "20            Good\n",
      "21       Very Good\n",
      "22       Very Good\n",
      "23       Very Good\n",
      "24       Very Good\n",
      "25       Very Good\n",
      "26         Premium\n",
      "27       Very Good\n",
      "28       Very Good\n",
      "29       Very Good\n",
      "           ...    \n",
      "53910      Premium\n",
      "53911      Premium\n",
      "53912      Premium\n",
      "53913         Good\n",
      "53914         Good\n",
      "53915        Ideal\n",
      "53916         Good\n",
      "53917    Very Good\n",
      "53918      Premium\n",
      "53919        Ideal\n",
      "53920    Very Good\n",
      "53921    Very Good\n",
      "53922    Very Good\n",
      "53923        Ideal\n",
      "53924        Ideal\n",
      "53925        Ideal\n",
      "53926        Ideal\n",
      "53927         Good\n",
      "53928      Premium\n",
      "53929        Ideal\n",
      "53930      Premium\n",
      "53931      Premium\n",
      "53932    Very Good\n",
      "53933    Very Good\n",
      "53934      Premium\n",
      "53935        Ideal\n",
      "53936         Good\n",
      "53937    Very Good\n",
      "53938      Premium\n",
      "53939        Ideal\n",
      "Name: cut, Length: 53940, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#carat\tcut\tcolor\tclarity\tdepth\ttable\tprice\tx\ty\tz\n",
    "print(dataset['cut'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the data\n",
    "\n",
    "### 1. Split data in training, validation and test\n",
    "A wise person said: \"friends don’t let friends use testing data for training\".  Set bellow the sizes of each set.\n",
    "\n",
    "**Note:**\n",
    "* **sklearn.model_selection.train_test_split(*arrays, **options)**  \n",
    "    Split arrays or matrices into random train and test subsets.  \n",
    "    See documentation:http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "\n",
    "### 2. Put the dataset into Numpy volume\n",
    "Categorical atributes are changed to integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_size:  53940\n",
      "train_size:  30000\n",
      "validation_size:  10000\n",
      "test_size:  13940\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'label_encoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-c09d23ca46d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategorical_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#if the feature is categorical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mtrain_volume\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcategorical_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mvalidation_volume\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcategorical_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mtest_volume\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcategorical_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'label_encoder' is not defined"
     ]
    }
   ],
   "source": [
    "#1. SPLIT DATASET\n",
    "data_size = 53940        #change values here\n",
    "train_size = 30000\n",
    "validation_size = 10000\n",
    "test_size = 13940\n",
    "\n",
    "nx = 9                   #number of features of the input\n",
    "ny = 1                   #number of fetures of the output\n",
    "\n",
    "train,test_validation = train_test_split(dataset, test_size = validation_size + test_size)\n",
    "validation, test = train_test_split(test_validation, test_size = test_size)\n",
    "\n",
    "print (\"data_size: \", data_size)\n",
    "print (\"train_size: \", train.shape[0])\n",
    "print (\"validation_size: \", validation.shape[0])\n",
    "print (\"test_size: \", test.shape[0])\n",
    "\n",
    "\n",
    "#2. SAVE THE PANDA'S DATAFRAME ON NUMPY ARRAYS\n",
    "categorical_labels = ['carat', 'cut', 'color', 'clarity', 'depth', 'table', 'price', 'x', 'y', 'z']\n",
    "\n",
    "train_volume = np.empty(train.shape)\n",
    "validation_volume = np.empty(validation.shape)\n",
    "test_volume = np.empty(test.shape)\n",
    "\n",
    "# For each feature, copy or transforms and copy (in categorical case) to the correspondent volume\n",
    "for i in range(len(categorical_labels)):\n",
    "    if( i >= 1 and i <= 3): #if the feature is categorical\n",
    "        train_volume [:,i] = label_encoder.fit_transform(train[categorical_labels[i]])\n",
    "        validation_volume[:, i] = label_encoder.fit_transform(validation[categorical_labels[i]])\n",
    "        test_volume[:, i] = label_encoder.fit_transform(test[categorical_labels[i]])\n",
    "    else:\n",
    "        train_volume[:,i] = train[categorical_labels[i]]\n",
    "        validation_volume[:,i] = validation[categorical_labels[i]]\n",
    "        test_volume[:,i] = test[categorical_labels[i]]\n",
    "\n",
    "# Separates the input from the label organize data in (number_features, number_of_examples)\n",
    "x_train = (train_volume[:, 0:9]).T\n",
    "y_train = (train_volume[:, 9].reshape(train_size,1)).T\n",
    "x_validation = validation_volume [:, 0:9].T\n",
    "y_validation = validation_volume [:,9].reshape(ny, validation_size)\n",
    "x_test = test_volume [:,0:9].T\n",
    "y_test = test_volume [:,9].reshape(test_size,1).T\n",
    "\n",
    "# Sanity check\n",
    "assert(x_train.shape == (nx, train_size))\n",
    "assert(y_train.shape == (ny, train_size))\n",
    "assert(x_validation.shape == (nx, validation_size))\n",
    "assert(y_validation.shape == (ny, validation_size))\n",
    "assert(x_test.shape == (nx, test_size))\n",
    "assert(y_test.shape == (ny, test_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression with gradient descent model\n",
    "Given a the following cost function J (w,b), where w is the wights and b is the bias. The goal is to iteratively minimze this function.\n",
    "$$ J(w,b) = \\frac{1}{2m}\\sum_{i}^{m}(y^{(i)} - ŷ^{(i)})^{2} $$\n",
    "$$ ŷ = wx + b$$\n",
    "**calculate the derivatives of the cost function update parameters**:\n",
    "$$\\frac{\\partial J(w,b)}{\\partial w} = -\\frac{1}{m}\\sum_{i = i}^{m} (y - ŷ)x$$\n",
    "$$\\frac{\\partial J(w,b)}{\\partial w} = -\\frac{1}{m}\\sum_{i = i}^{m} (y - ŷ)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(X):\n",
    "    \"\"\"\n",
    "    Arguments: Receives the input array X shape (nx, m), where nx is the number of features and m\n",
    "    the number of training examples.\n",
    "    Returns: the parameteres arrays \n",
    "    \"\"\"\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
